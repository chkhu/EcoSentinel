{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EcoSentinel: 基于ERNIE的森林保护巡视决策系统\n",
    "\n",
    "## 一、项目背景\n",
    "\n",
    "根据国家林业和草原局的公开信息和统计数据，我国大多省市的森林保护工作主要依赖人工筛查、响应，存在成本高、效率低和防护效果差的问题。\n",
    "本项目基于飞桨文心大模型(ERNIE BOT)，依靠林业知识库进行“微调”训练，辅助使用 PaddleX套件的目标检测YOLO模型，构建 EcoSentinel —— 一个“**多模态信息-图语义分析-LLM-行动决策建议**”的端到端智慧森林巡视系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T12:30:58.450019Z",
     "iopub.status.busy": "2023-09-19T12:30:58.449534Z",
     "iopub.status.idle": "2023-09-19T12:30:58.468317Z",
     "shell.execute_reply": "2023-09-19T12:30:58.467206Z",
     "shell.execute_reply.started": "2023-09-19T12:30:58.449994Z"
    }
   },
   "source": [
    "## 二、技术原理\n",
    "\n",
    "这个项目分为两个主要任务。\n",
    "\n",
    "第一个任务，使用 Salesforce 开源的 **BLIP** 模型，将上传的图像解析为描述性文本；利用百度飞桨的 ERNIE 模型配合定制知识库，分析图像解析得到的文本，生成专业林业管理员视角的专业行动建议。\n",
    "\n",
    "该项目还结合了 飞桨PaddleX 进行目标检测，以便更精确地定位烟火源。这是我们的第二个任务。\n",
    "\n",
    "整个工作流程通过 Gradio 提供了一个交互式的 GUI 应用。\n",
    "\n",
    "![avatar](https://img-blog.csdnimg.cn/7ec55908bced420fbcfe55516948a975.png)\n",
    "\n",
    "> 百度飞桨开源的ERNIE Bot(文心大模型)，是基于知识增强的持续学习语义理解的大语言模型。根据最新评估数据，文心大模型已经中文任务以及多项指标上超越了OpenAI GPT4.\n",
    "\n",
    "> PaddleX是飞桨开源的全流程开发工具，集飞桨核心框架、模型库、工具及组件等深度学习开发所需全部能力于一身，并提供简明易懂的Python API，方便用户根据实际生产需求进行直接调用或二次开发，大幅降低了深度学习任务上手的门槛。\n",
    "\n",
    "本项目代码已经开源，发布在Github上，点 👉[这里](https://github.com/chkhu/EcoSentinel)👈 访问"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、效果展示\n",
    "\n",
    "本项目的介绍视频：点 👉[这里]()👈 跳转\n",
    "\n",
    "<img src=\"https://img-blog.csdnimg.cn/13bb06c8bc95421bb8345f9a8642c8d0.jpeg\" alt=\"ScreenShot.jpg\" style=\"zoom:40%;\" />\n",
    "\n",
    "（计划后续将会部署到Hugging Face上。）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （二）任务一：大模型任务\n",
    "\n",
    "\n",
    "对于大模型任务，我们首先使用salesforce开源的image2text-captioning BLIP模型，对我们上传的图像进行解析，返回一段描述文本。然后，拼接request，通过api向文心发出request，得到专业的林业管理员视角下的行动建议。\n",
    "\n",
    "如果你希望直接运行python源代码，可以`python app/app_server.py` 直接运行我们提供的源代码（未嵌入视觉模块的版本）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.1 导入需要的库\n",
    "\n",
    "\n",
    "以下是该项目需要使用的模块。若为安装，请根据log提示进行安装。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:04:58.801277Z",
     "iopub.status.busy": "2023-09-29T12:04:58.800668Z",
     "iopub.status.idle": "2023-09-29T12:05:02.071131Z",
     "shell.execute_reply": "2023-09-29T12:05:02.070000Z",
     "shell.execute_reply.started": "2023-09-29T12:04:58.801236Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (7.6.5)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (5.5.0)\r\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (6.9.1)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (5.4.0)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (3.0.3)\r\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (3.5.2)\r\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (7.34.0)\r\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.5)\r\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\r\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\r\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (4.7.0)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.1.0)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (2.13.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (56.2.0)\r\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.16.0)\r\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: jupyter_core in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.11.1)\r\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.7.0)\r\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.7.1)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.3.0)\r\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (1.3.10)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (22.1.0)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (5.9.0)\r\n",
      "Requirement already satisfied: entrypoints in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\r\n",
      "Requirement already satisfied: pyzmq>=23.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (23.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.0)\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\r\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.15.0)\r\n",
      "Requirement already satisfied: prometheus_client in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.14.1)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.16.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.1.7)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.8.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.2)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.13)\r\n",
      "Requirement already satisfied: defusedxml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.0.1)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.11.1)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.3.2.post1)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install ipywidgets\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:02.073818Z",
     "iopub.status.busy": "2023-09-29T12:05:02.073132Z",
     "iopub.status.idle": "2023-09-29T12:05:04.437370Z",
     "shell.execute_reply": "2023-09-29T12:05:04.436406Z",
     "shell.execute_reply.started": "2023-09-29T12:05:02.073788Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests  # 用于发送 HTTP 请求\n",
    "import json  # 用于处理 JSON 数据\n",
    "import gradio as gr  # 用gradio创建图形用户界面\n",
    "import io  # 用于处理字节流\n",
    "from PIL import Image # 用于处理图像\n",
    "import numpy as np \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 API和知识库的准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明👇：\n",
    "\n",
    "以text-concatenation的形式对ERNIE模型(文心大模型)进行“角色微调”。使用的“微调”材料采自我们搜集筛选的林业安全管理知识库。我们将这些材料和BLIP模型得到的描述文本进行拼接后作为我们的request发送给文心。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:04.439761Z",
     "iopub.status.busy": "2023-09-29T12:05:04.438691Z",
     "iopub.status.idle": "2023-09-29T12:05:04.445344Z",
     "shell.execute_reply": "2023-09-29T12:05:04.444451Z",
     "shell.execute_reply.started": "2023-09-29T12:05:04.439715Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 百度AI的API Key和Secret Key，用于链接文心大模型\n",
    "SC_API_KEY = \"*************************\"\n",
    "SC_SECRET_KEY = \"*************************\"\n",
    "\n",
    "# 连接 salesforce BLIP 的inference API 准备\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "blip_headers = {\"Authorization\": \"Bearer api_org_*************************\"}\n",
    "\n",
    "# 自定义的知识库字符串，用于个性化定制文心大模型\n",
    "knowledge_base = \"\"  \n",
    "\n",
    "# 为应对多次分析请求，初始化一个列表来存储所有生成的文本。\n",
    "generated_texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 功能函数的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:04.447631Z",
     "iopub.status.busy": "2023-09-29T12:05:04.447255Z",
     "iopub.status.idle": "2023-09-29T12:05:04.573292Z",
     "shell.execute_reply": "2023-09-29T12:05:04.572493Z",
     "shell.execute_reply.started": "2023-09-29T12:05:04.447592Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 文心API的调用函数\n",
    "# INPUT：用户的输入文本\n",
    "# OUTPUT：文心的回答文本\n",
    "def main_app(input_text):\n",
    "    # 拼接 URL，文心的base_url + access token, 只有拥有有效的access_token，才能成功调用文心API。\n",
    "    # get_access_token()函数会发送一个 HTTP POST 请求到百度 获取access_token。 具体的实现在下面。\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token=\" + get_access_token()\n",
    "    payload = json.dumps({  # 将 Python 对象转换编码成 JSON 字符串\n",
    "        \"messages\": [   # 拼接出完整query，包含三部分：引导词、知识库、场景描述\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"假如你是一个专业林业安全管理员，熟知：\" + knowledge_base + \n",
    "                    \"要根据下面的描述给出一个解决方案，并且回答中只需含有解决方案：\" + \n",
    "                    input_text,\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "    headers = { # 设置 HTTP 请求的头部信息\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload) # 发送 HTTP POST 请求，返回一个response对象\n",
    "    result = response.json().get(\"result\")  # 从response对象中提取出 JSON 数据（回答文本）\n",
    "    print(\"WENXIN RESPONSE:\\n\" + result + \"\\n\")\n",
    "    return result\n",
    "\n",
    "# 获取百度AI的access_token\n",
    "# INPUT：无，但需要使用到前面定义的 SC_API_KEY 和 SC_SECRET_KEY\n",
    "# OUTPUT：access_token\n",
    "def get_access_token(): \n",
    "    url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={SC_API_KEY}&client_secret={SC_SECRET_KEY}\" # 拼接 request URL\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload) # 发送 HTTP POST 请求，返回一个response对象\n",
    "    print(\"ACCESS_TOKEN OBTAINED: \\n\" + response.text + \"\\n\")\n",
    "    return str(response.json().get(\"access_token\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明👇：\n",
    "\n",
    "我们将会使用BLIP模型实现图生文任务。\n",
    "\n",
    "> BLIP 是由Salesforce开发的一个非常强大的视觉语义理解模型,官方提供了hugging face workspace和了非常便捷的off-the-shelf api服务,帮助开发者快速应用这一模型能力。\n",
    "> 本项目中通过inference API的方式调用BLIP模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:04.575555Z",
     "iopub.status.busy": "2023-09-29T12:05:04.575225Z",
     "iopub.status.idle": "2023-09-29T12:05:04.581304Z",
     "shell.execute_reply": "2023-09-29T12:05:04.580663Z",
     "shell.execute_reply.started": "2023-09-29T12:05:04.575529Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BLIP API的调用函数\n",
    "def query(image_data):\n",
    "    response = requests.post(API_URL, headers=blip_headers, data=image_data)\n",
    "    return response.json()\n",
    "\n",
    "def judge_query(image_data):\n",
    "    response = requests.post(API_URL_VIT, headers=headers_VIT, data=image_data)\n",
    "    return response.json()\n",
    "\n",
    "def judge(input_image):\n",
    "    # 将输入的input_image(numpy数组类型)转成query函数可以接受的Bytes类型\n",
    "    img = Image.fromarray(input_image.astype(np.uint8))  # 需要转换为 uint8，范围 [0, 255]    \n",
    "    img_byte_arr = io.BytesIO()  # 创建一个字节流对象\n",
    "    img.save(img_byte_arr, format='PNG')  # 将图像保存到字节流中，可以选择不同的格式，例如 'JPEG'，这里用 'PNG'\n",
    "    img_byte_arr = img_byte_arr.getvalue()  # 获取字节流的值\n",
    "\n",
    "    output = judge_query(img_byte_arr)\n",
    "\n",
    "    # # 检查输出是否包含错误信息\n",
    "    # if 'error' in output:\n",
    "    #     # 处理错误情况，例如返回错误信息或重试请求\n",
    "    #     return f\"Error: {output['error']}\"\n",
    "\n",
    "    # # DEBUG\n",
    "    print(\"✨✨✨✨✨✨✨✨✨VIT output:\", output)\n",
    "\n",
    "    # 如果没有错误，则格式化输出\n",
    "    formatted_output = \"烟火元素置信度分析结果：\\n\"\n",
    "\n",
    "    # 提取出output中label值为Normal、Fire、Smoke的置信度\n",
    "    for item in output:\n",
    "        if item['label'] == 'Normal':\n",
    "            normal_score = item['score']\n",
    "            formatted_output += f\"Normal置信度: {item['score']}\\n\"\n",
    "        elif item['label'] == 'Fire':\n",
    "            fire_score = item['score']\n",
    "            formatted_output += f\"Fire置信度: {item['score']}\\n\"\n",
    "        elif item['label'] == 'Smoke':\n",
    "            smoke_score = item['score']\n",
    "            formatted_output += f\"Smoke置信度: {item['score']}\\n\"\n",
    "\n",
    "    formatted_output += \"\\n烟火目标判断结果：\\n\"\n",
    "    if fire_score > normal_score or smoke_score > normal_score:\n",
    "        formatted_output += \"⚠️存在火情\"\n",
    "    else:\n",
    "        formatted_output += \"🍃不存在火情\"\n",
    "\n",
    "    judgement_output = formatted_output\n",
    "\n",
    "    # 最后，返回生成的文本\n",
    "    return judgement_output\n",
    "\n",
    "\n",
    "\n",
    "# 图片分析函数\n",
    "# INPUT：用户上传的图片\n",
    "# OUTPUT：图片分析文本\n",
    "def image_analysis(input_image):\n",
    "    # # DEBUG: 保存input_image到本地\n",
    "    # cv2.imwrite('temp.jpg', input_image)\n",
    "    # print(\"IMAGE ARRAY MAX VALUE\" + str(input_image.max())) # 255\n",
    "\n",
    "    # 将输入的input_image(numpy数组类型)转成query函数可以接受的Bytes类型\n",
    "    img = Image.fromarray(input_image.astype(np.uint8))  # 需要转换为 uint8，范围 [0, 255]    \n",
    "    img_byte_arr = io.BytesIO()  # 创建一个字节流对象\n",
    "    img.save(img_byte_arr, format='PNG')  # 将图像保存到字节流中，可以选择不同的格式，例如 'JPEG'，这里用 'PNG'\n",
    "    img_byte_arr = img_byte_arr.getvalue()  # 获取字节流的值\n",
    "\n",
    "    # 调用 query 函数\n",
    "    output = query(img_byte_arr)\n",
    "\n",
    "    # # DEBUG\n",
    "    # print(\"TYPE OF OUTPUT OF QUERY\\n\")\n",
    "    # print(type(output)) # list\n",
    "    \n",
    "    # 取出列表的0号元素，然后用 ['generated_text'] 取出字典中的值\n",
    "    newly_generated_text = output[0]['generated_text'] \n",
    "    generated_texts.append(newly_generated_text)\n",
    "    generated_text = generated_texts[-1] #  取列表的最后一个元素，确保每次都是最新的文本\n",
    "\n",
    "    # 最后，返回生成的文本\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们对视频的处理：将其分片并抽取几帧，对这些帧逐一分析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_analysis(input_video):\n",
    "    # 思路是抽取视频关键帧，然后对关键帧进行分析，最后将所有的分析结果拼接起来\n",
    "    # 1. 读取视频\n",
    "    vidcap = cv2.VideoCapture(input_video)\n",
    "    # 获取视频总帧数\n",
    "    vidFrame = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))  \n",
    "    # 视频时间\n",
    "    if(vidFrame==0):\n",
    "        return \"视频无效，请重新上传！\"\n",
    "    vidTime = vidFrame / vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    maxFrame = 10\n",
    "    minInterval = 0.5 \n",
    "    # 实际每几秒处理一次\n",
    "    intervalTime = max(minInterval, vidTime / maxFrame)\n",
    "    # 实际每几帧处理一次\n",
    "    intervalFrame = int(intervalTime * vidcap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # 2. 抽取帧处理\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "\n",
    "    video_analysis_result = []\n",
    "    while success:\n",
    "        # 2.1 处理帧\n",
    "        result_of_frame = image_analysis(image)\n",
    "        video_analysis_result.append(result_of_frame)\n",
    "        # 2.2 读取下一帧\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, count * intervalFrame)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "        print(\"FRAME \" + str(count) + \" ANALYZED: \"+ result_of_frame)\n",
    "    # 3. 拼接结果\n",
    "    return \"\\n\".join(video_analysis_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio搭建用户界面\n",
    "\n",
    "最后我们基于graddio封装了我们一系列模型的工作管线，提供了简单易用可交互的GUI应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:04.582713Z",
     "iopub.status.busy": "2023-09-29T12:05:04.582202Z",
     "iopub.status.idle": "2023-09-29T12:05:08.241827Z",
     "shell.execute_reply": "2023-09-29T12:05:08.241027Z",
     "shell.execute_reply.started": "2023-09-29T12:05:04.582688Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\r\n",
      "\r\n",
      "To create a public link, set `share=True` in `launch()`.\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Gradio UI ###\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Tab(\"上传图片\"):\n",
    "            image_input = gr.Image()\n",
    "            img_analysis_button = gr.Button(\"分析图片\")\n",
    "        with gr.Tab(\"上传视频\"):\n",
    "            video_input = gr.Video()\n",
    "            video_analysis_button = gr.Button(\"分析视频\")\n",
    "        analysis_result = gr.Textbox(label=\"分析结果\")\n",
    "        \n",
    "        \n",
    "    with gr.Tab(\"建议\"):\n",
    "        text_output = gr.Textbox(label=\"输出\")\n",
    "    text_button = gr.Button(\"获取建议\")\n",
    "\n",
    "    with gr.Tab(\"烟火元素置信度分析(适用林火)\"):  # 新增Row\n",
    "        judge_image_output = gr.Textbox(label=\"分析判断结果\", image_mode='fixed', width=600)\n",
    "    judge_button = gr.Button(\"分析判断图片\")\n",
    "        \n",
    "    with gr.Tab(\"烟火目标检测可视化(适用林火)\"):  # 新增Row\n",
    "        detected_image_output = gr.Image(label=\"目标检测结果\", image_mode='fixed', width=600)  # 新增图像输出组件\n",
    "    detect_button = gr.Button(\"显示目标检测结果\")  # 新增按钮\n",
    "    \n",
    "    img_analysis_button.click(image_analysis, inputs=image_input, outputs=analysis_result) # 将按钮与image_analysis函数关联\n",
    "    video_analysis_button.click(video_analysis, inputs=video_input, outputs=analysis_result) # 将按钮与video_analysis函数关联\n",
    "\n",
    "    text_button.click(main_app, inputs=analysis_result, outputs=text_output) # 将按钮与main_app函数关联\n",
    "    \n",
    "    detect_button.click(detect, inputs=image_input, outputs=detected_image_output)  # 将按钮与detect函数关联\n",
    "    judge_button.click(judge, inputs=image_input, outputs=judge_image_output)  # 将按钮与judge_query函数关联\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你应该可以预期看到类似下面的界面。\n",
    "\n",
    "<img src=\"https://img-blog.csdnimg.cn/a0ba826f892d4da38c41c982e840ef0d.png\" alt=\"base_gui.png\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常情况下，上面的log将会显示本地预览demo的接口，点击即可进行测试。\n",
    "\n",
    "值得指出的是，我们的项目允许用户根据实际需要，**优化recompose编辑BLIP生成的输出captioning**，来应对描述质量不够稳定的问题。这一过程在演示视频的demo中有展示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （二）任务二：视觉任务\n",
    "\n",
    "\n",
    "为了实现对火灾场景监测效果的进一步优化，我们为林火场景特别引入了百度飞桨开源套件PaddleX的目标检测模型YOLO，对输入航拍中的烟火进行检测定位，为林业消防部门提供精确的指引。部分操作参考基于AI studio开放项目“PaddleX的火焰检测与识别”。\n",
    "\n",
    "### 2.1 安装PaddleX\n",
    "\n",
    "\n",
    "本任务要求PaddleX的任务不超过2.0.0，因此在命令中强制版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:08.243268Z",
     "iopub.status.busy": "2023-09-29T12:05:08.242917Z",
     "iopub.status.idle": "2023-09-29T12:05:10.743500Z",
     "shell.execute_reply": "2023-09-29T12:05:10.740570Z",
     "shell.execute_reply.started": "2023-09-29T12:05:08.243242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.24.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn) (1.20.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn) (1.6.3)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:05:10.746772Z",
     "iopub.status.busy": "2023-09-29T12:05:10.745612Z",
     "iopub.status.idle": "2023-09-29T12:05:19.002046Z",
     "shell.execute_reply": "2023-09-29T12:05:19.000954Z",
     "shell.execute_reply.started": "2023-09-29T12:05:10.746695Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Collecting paddlex<2.0.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d6/a2/07435f4aa1e51fe22bdf06c95d03bf1b78b7bc6625adbb51e35dc0804cc7/paddlex-1.3.11-py3-none-any.whl (516 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.0/517.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (4.1.1.26)\r\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (0.0)\r\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (2.2.0)\r\n",
      "Collecting paddleslim==1.1.1\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d1/77/e257227bed9a70ff0d35a4a3c4e70ac2d2362c803834c4c52018f7c4b762/paddleslim-1.1.1-py2.py3-none-any.whl (145 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.3/145.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting shapely>=1.7.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1d/a4/931d0780f31f3ea8c4f9ef6464a2825137c5241e6707a5fb03bef760a7eb/shapely-2.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (3.0.8)\r\n",
      "Collecting paddlehub==2.1.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7a/29/3bd0ca43c787181e9c22fe44b944b64d7fcb14ce66d3bf4602d9ad2ac76c/paddlehub-2.1.0-py3-none-any.whl (211 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (5.1.2)\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/27/37/9a47974f4176d10d5304ead7f4c1ddf6e4148405d4e4c5414c4c68967295/pycocotools-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.3/403.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (4.36.1)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (0.4.4)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (5.7.2)\r\n",
      "Collecting xlwt\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (3.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (4.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (1.20.3)\r\n",
      "Requirement already satisfied: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (1.1.1)\r\n",
      "Collecting paddle2onnx>=0.5.1\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/bd/cd/a52d50852ca8ca29529fbe367e1b3f5f9799a78bd66b33dd70e31987afb1/paddle2onnx-1.0.9-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: paddlenlp>=2.0.0rc5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (2.0.7)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (8.2.0)\r\n",
      "Requirement already satisfied: gunicorn>=19.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (20.0.4)\r\n",
      "Requirement already satisfied: easydict in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (1.9)\r\n",
      "Requirement already satisfied: gitpython in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (3.1.14)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (2.2.3)\r\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (23.2.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (21.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (3.0.12)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.1.5)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (0.8.53)\r\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (4.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (2.22.0)\r\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (0.7.1.1)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.0.0)\r\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (3.20.1)\r\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.21.0)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.16.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->paddlex<2.0.0) (0.24.2)\r\n",
      "Requirement already satisfied: importlib-metadata<4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (4.2.0)\r\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (0.6.1)\r\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (2.4.0)\r\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (2.8.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex<2.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex<2.0.0) (3.0.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex<2.0.0) (0.16.0)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex<2.0.0) (7.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex<2.0.0) (2019.3)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex<2.0.0) (2.8.0)\r\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gunicorn>=19.10.0->paddlehub==2.1.0->paddlex<2.0.0) (56.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex<2.0.0) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex<2.0.0) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex<2.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.1.0->paddlex<2.0.0) (0.10.0)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (1.2.2)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (0.70.11.1)\r\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (0.42.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (2.9.0)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex<2.0.0) (3.9.9)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex<2.0.0) (0.18.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitpython->paddlehub==2.1.0->paddlex<2.0.0) (4.0.5)\r\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (1.3.4)\r\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (0.10.0)\r\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (1.4.10)\r\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (2.0.1)\r\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (16.7.9)\r\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (1.3.0)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (1.25.6)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (2019.9.11)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlex<2.0.0) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlex<2.0.0) (1.6.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlex<2.0.0) (0.14.1)\r\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython->paddlehub==2.1.0->paddlex<2.0.0) (3.0.5)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (4.3.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (3.8.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub==2.1.0->paddlex<2.0.0) (2.0.1)\r\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (0.3.3)\r\n",
      "Installing collected packages: xlwt, paddle2onnx, shapely, paddleslim, pycocotools, paddlehub, paddlex\r\n",
      "  Attempting uninstall: paddlehub\r\n",
      "    Found existing installation: paddlehub 2.0.4\r\n",
      "    Uninstalling paddlehub-2.0.4:\r\n",
      "      Successfully uninstalled paddlehub-2.0.4\r\n",
      "Successfully installed paddle2onnx-1.0.9 paddlehub-2.1.0 paddleslim-1.1.1 paddlex-1.3.11 pycocotools-2.0.7 shapely-2.0.1 xlwt-1.3.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install \"paddlex<2.0.0\" -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据集\n",
    "\n",
    "实验过程中，我们比对测试了开放数据集和自建数据集的效果，最终选择了下面这个数据集。\n",
    "\n",
    "#### 2.2.1 解压并查看数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:07:15.165924Z",
     "iopub.status.busy": "2023-09-29T12:07:15.164952Z",
     "iopub.status.idle": "2023-09-29T12:07:15.169018Z",
     "shell.execute_reply": "2023-09-29T12:07:15.168267Z",
     "shell.execute_reply.started": "2023-09-29T12:07:15.165888Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! unzip -oq /home/aistudio/data/fire.zip -d /home/aistudio/data/\n",
    "# ! tree /home/aistudio/data/fire -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2.2 数据集划分\n",
    "运行命令，在指定的目录（home/aistudio//fire）下寻找 VOC 格式的数据集，并将其划分为三个子集：训练集、验证集和测试集。\n",
    "\n",
    "划分比例是：训练集占 70%（100% - 20% - 10%），验证集占 20%，测试集占 10%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:07:17.784775Z",
     "iopub.status.busy": "2023-09-29T12:07:17.783774Z",
     "iopub.status.idle": "2023-09-29T12:07:20.170280Z",
     "shell.execute_reply": "2023-09-29T12:07:20.169214Z",
     "shell.execute_reply.started": "2023-09-29T12:07:17.784735Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Requirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (3.0.4)\r\n",
      "\r\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.2.1\r\n",
      "[notice] To update, run: pip install --upgrade pip\r\n"
     ]
    }
   ],
   "source": [
    "! pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:07:23.367838Z",
     "iopub.status.busy": "2023-09-29T12:07:23.367260Z",
     "iopub.status.idle": "2023-09-29T12:07:23.373194Z",
     "shell.execute_reply": "2023-09-29T12:07:23.372421Z",
     "shell.execute_reply.started": "2023-09-29T12:07:23.367801Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:07:47.520607Z",
     "iopub.status.busy": "2023-09-29T12:07:47.520003Z",
     "iopub.status.idle": "2023-09-29T12:07:49.413447Z",
     "shell.execute_reply": "2023-09-29T12:07:49.412392Z",
     "shell.execute_reply.started": "2023-09-29T12:07:47.520570Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Split Done.\r\n",
      "Train samples: 345\r\n",
      "Eval samples: 98\r\n",
      "Test samples: 49\r\n",
      "Split files saved in /home/aistudio/data/fire\r\n"
     ]
    }
   ],
   "source": [
    "# paddlex 自带数据集划分工具\n",
    "! paddlex --split_dataset --format VOC --dataset_dir /home/aistudio/data/fire --val_value 0.2 --test_value 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 模型训练\n",
    "\n",
    "#### 2.3.1 预先配置\n",
    "\n",
    "导入需要的工具包，包括PaddleX套件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:08:04.766495Z",
     "iopub.status.busy": "2023-09-29T12:08:04.765518Z",
     "iopub.status.idle": "2023-09-29T12:08:04.773123Z",
     "shell.execute_reply": "2023-09-29T12:08:04.772283Z",
     "shell.execute_reply.started": "2023-09-29T12:08:04.766457Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: \r\n",
      "This call to matplotlib.use() has no effect because the backend has already\r\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\r\n",
      "or matplotlib.backends is imported for the first time.\r\n",
      "\r\n",
      "The backend was *originally* set to 'module://matplotlib_inline.backend_inline' by the following code:\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n",
      "    app.launch_new_instance()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\r\n",
      "    app.start()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 677, in start\r\n",
      "    self.io_loop.start()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\r\n",
      "    self.asyncio_loop.run_forever()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\r\n",
      "    self._run_once()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\r\n",
      "    handle._run()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n",
      "    self._context.run(self._callback, *self._args)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\r\n",
      "    await self.process_one()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\r\n",
      "    await dispatch(*args)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\r\n",
      "    await result\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\r\n",
      "    reply_content = await reply_content\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\r\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\r\n",
      "    return super().run_cell(*args, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\r\n",
      "    self.events.trigger('post_run_cell', result)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/events.py\", line 89, in trigger\r\n",
      "    func(*args, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib_inline/backend_inline.py\", line 222, in configure_once\r\n",
      "    activate_matplotlib(backend)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 359, in activate_matplotlib\r\n",
      "    plt.switch_backend(backend)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\r\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py\", line 1422, in use\r\n",
      "    reload(sys.modules['matplotlib.backends'])\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/__init__.py\", line 169, in reload\r\n",
      "    _bootstrap._exec(spec, module)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\r\n",
      "    line for line in traceback.format_stack()\r\n",
      "\r\n",
      "\r\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.11\r\n"
     ]
    }
   ],
   "source": [
    "# 默认使用0号GPU卡（无GPU情况将会调用cpu训练）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "print(pdx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据处理流程，其中训练和测试需分别定义，训练过程包括了部分测试过程中不需要的数据增强操作，如在本示例中，训练过程使用了`MixupImage`、`RandomDistort`、`RandomExpand`、`RandomCrop`和`RandomHorizontalFlip`共5种数据增强方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:08:21.674094Z",
     "iopub.status.busy": "2023-09-29T12:08:21.673071Z",
     "iopub.status.idle": "2023-09-29T12:08:21.679428Z",
     "shell.execute_reply": "2023-09-29T12:08:21.678557Z",
     "shell.execute_reply.started": "2023-09-29T12:08:21.674051Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddlex as pdx\n",
    "from paddlex.det import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.MixupImage(mixup_epoch=250),\n",
    "    transforms.RandomDistort(),\n",
    "    transforms.RandomExpand(),\n",
    "    transforms.RandomCrop(),\n",
    "    transforms.Resize(target_size=608, interp='RANDOM'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "# 验证集部分只需要resize和normalize即可\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize(target_size=608, interp='CUBIC'),\n",
    "    transforms.Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 指定训练数据路径\n",
    "\n",
    "首先查看目前的数据集目录的清单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:08:37.391005Z",
     "iopub.status.busy": "2023-09-29T12:08:37.390133Z",
     "iopub.status.idle": "2023-09-29T12:08:37.635560Z",
     "shell.execute_reply": "2023-09-29T12:08:37.634424Z",
     "shell.execute_reply.started": "2023-09-29T12:08:37.390955Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations  labels.txt     train_list.txt\r\n",
      "JPEGImages   test_list.txt  val_list.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/aistudio/data/fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于数据集为VOC格式，因此采用`pdx.datasets.VOCDetection`来加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:09:21.051932Z",
     "iopub.status.busy": "2023-09-29T12:09:21.051140Z",
     "iopub.status.idle": "2023-09-29T12:09:21.584111Z",
     "shell.execute_reply": "2023-09-29T12:09:21.583330Z",
     "shell.execute_reply.started": "2023-09-29T12:09:21.051890Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:09:21 [INFO]\tStarting to read file list from dataset...\r\n",
      "2023-09-29 20:09:21 [INFO]\t345 samples in file /home/aistudio/data/fire/train_list.txt\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "2023-09-29 20:09:21 [INFO]\tStarting to read file list from dataset...\r\n",
      "2023-09-29 20:09:21 [INFO]\t98 samples in file /home/aistudio/data/fire/val_list.txt\r\n",
      "creating index...\r\n",
      "index created!\r\n"
     ]
    }
   ],
   "source": [
    "# 此处的数据集路径全部采用绝对路径\n",
    "\n",
    "train_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='/home/aistudio/data/fire',\n",
    "    file_list='/home/aistudio/data/fire/train_list.txt',\n",
    "    label_list='/home/aistudio/data/fire/labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "eval_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='/home/aistudio/data/fire',\n",
    "    file_list='/home/aistudio/data/fire/val_list.txt',\n",
    "    label_list='/home/aistudio/data/fire/labels.txt',\n",
    "    transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 开始训练\n",
    "\n",
    "使用本数据集V100训练，需要约15分钟。模型训练过程每间隔save_interval_epochs轮次会保存一次模型在save_dir目录下，同时在保存的过程中也会在验证数据集上计算相关指标。\n",
    "\n",
    "你可以根据自己的需要调整 epoch, interval, lr 等参数。最后的训练耗时与模型效果将会有所差异。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:09:26.258027Z",
     "iopub.status.busy": "2023-09-29T12:09:26.257047Z",
     "iopub.status.idle": "2023-09-29T12:24:09.878249Z",
     "shell.execute_reply": "2023-09-29T12:24:09.868100Z",
     "shell.execute_reply.started": "2023-09-29T12:09:26.257992Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:706: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n",
      "  elif dtype == np.bool:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:09:28 [INFO]\tDownloading DarkNet53_ImageNet1k_pretrained.tar from https://paddle-imagenet-models-name.bj.bcebos.com/DarkNet53_ImageNet1k_pretrained.tar\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162940/162940 [00:06<00:00, 23293.95KB/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:09:35 [INFO]\tDecompressing output/yolov3_darknet53/pretrain/DarkNet53_ImageNet1k_pretrained.tar...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0929 20:09:35.996111   185 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\r\n",
      "W0929 20:09:36.001534   185 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:09:39 [INFO]\tLoad pretrain weights from output/yolov3_darknet53/pretrain/DarkNet53_ImageNet1k_pretrained.\r\n",
      "2023-09-29 20:09:40 [INFO]\tThere are 260 varaibles in output/yolov3_darknet53/pretrain/DarkNet53_ImageNet1k_pretrained are loaded.\r\n",
      "2023-09-29 20:10:01 [INFO]\t[TRAIN] Epoch=1/40, Step=28/28, loss=123.86161, lr=3e-06, time_each_step=0.37s, eta=0:6:59\r\n",
      "2023-09-29 20:10:01 [INFO]\t[TRAIN] Epoch 1 finished, loss=4882.686035, lr=2e-06 .\r\n",
      "2023-09-29 20:10:20 [INFO]\t[TRAIN] Epoch=2/40, Step=28/28, loss=23.682301, lr=7e-06, time_each_step=0.46s, eta=0:13:19\r\n",
      "2023-09-29 20:10:20 [INFO]\t[TRAIN] Epoch 2 finished, loss=52.064514, lr=5e-06 .\r\n",
      "2023-09-29 20:10:39 [INFO]\t[TRAIN] Epoch=3/40, Step=28/28, loss=20.215176, lr=1e-05, time_each_step=0.46s, eta=0:11:54\r\n",
      "2023-09-29 20:10:39 [INFO]\t[TRAIN] Epoch 3 finished, loss=25.915695, lr=9e-06 .\r\n",
      "2023-09-29 20:10:58 [INFO]\t[TRAIN] Epoch=4/40, Step=28/28, loss=19.851086, lr=1.4e-05, time_each_step=0.45s, eta=0:12:5\r\n",
      "2023-09-29 20:10:58 [INFO]\t[TRAIN] Epoch 4 finished, loss=25.16997, lr=1.2e-05 .\r\n",
      "2023-09-29 20:11:18 [INFO]\t[TRAIN] Epoch=5/40, Step=28/28, loss=23.291267, lr=1.7e-05, time_each_step=0.45s, eta=0:11:19\r\n",
      "2023-09-29 20:11:18 [INFO]\t[TRAIN] Epoch 5 finished, loss=23.481173, lr=1.6e-05 .\r\n",
      "2023-09-29 20:11:39 [INFO]\t[TRAIN] Epoch=6/40, Step=28/28, loss=20.6462, lr=2.1e-05, time_each_step=0.47s, eta=0:11:43\r\n",
      "2023-09-29 20:11:39 [INFO]\t[TRAIN] Epoch 6 finished, loss=22.266203, lr=1.9e-05 .\r\n",
      "2023-09-29 20:11:58 [INFO]\t[TRAIN] Epoch=7/40, Step=28/28, loss=24.886547, lr=2.4e-05, time_each_step=0.46s, eta=0:11:43\r\n",
      "2023-09-29 20:11:58 [INFO]\t[TRAIN] Epoch 7 finished, loss=20.892664, lr=2.3e-05 .\r\n",
      "2023-09-29 20:12:20 [INFO]\t[TRAIN] Epoch=8/40, Step=28/28, loss=23.13496, lr=2.8e-05, time_each_step=0.51s, eta=0:10:20\r\n",
      "2023-09-29 20:12:20 [INFO]\t[TRAIN] Epoch 8 finished, loss=19.919418, lr=2.6e-05 .\r\n",
      "2023-09-29 20:12:42 [INFO]\t[TRAIN] Epoch=9/40, Step=28/28, loss=20.830555, lr=3.1e-05, time_each_step=0.46s, eta=0:11:37\r\n",
      "2023-09-29 20:12:42 [INFO]\t[TRAIN] Epoch 9 finished, loss=20.497641, lr=3e-05 .\r\n",
      "2023-09-29 20:13:01 [INFO]\t[TRAIN] Epoch=10/40, Step=28/28, loss=15.981938, lr=3.5e-05, time_each_step=0.45s, eta=0:11:10\r\n",
      "2023-09-29 20:13:01 [INFO]\t[TRAIN] Epoch 10 finished, loss=19.93096, lr=3.3e-05 .\r\n",
      "2023-09-29 20:13:01 [INFO]\tStart to evaluating(total_samples=98, total_steps=9)...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:08<00:00,  1.00it/s]\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/utils/detection_eval.py:497: UserWarning: \r\n",
      "This call to matplotlib.use() has no effect because the backend has already\r\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\r\n",
      "or matplotlib.backends is imported for the first time.\r\n",
      "\r\n",
      "The backend was *originally* set to 'module://matplotlib_inline.backend_inline' by the following code:\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n",
      "    app.launch_new_instance()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\r\n",
      "    app.start()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 677, in start\r\n",
      "    self.io_loop.start()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\r\n",
      "    self.asyncio_loop.run_forever()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\r\n",
      "    self._run_once()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\r\n",
      "    handle._run()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n",
      "    self._context.run(self._callback, *self._args)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\r\n",
      "    await self.process_one()\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\r\n",
      "    await dispatch(*args)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\r\n",
      "    await result\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\r\n",
      "    reply_content = await reply_content\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\r\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\r\n",
      "    return super().run_cell(*args, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2981, in run_cell\r\n",
      "    self.events.trigger('post_run_cell', result)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/events.py\", line 89, in trigger\r\n",
      "    func(*args, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib_inline/backend_inline.py\", line 222, in configure_once\r\n",
      "    activate_matplotlib(backend)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 359, in activate_matplotlib\r\n",
      "    plt.switch_backend(backend)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\r\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py\", line 1422, in use\r\n",
      "    reload(sys.modules['matplotlib.backends'])\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/__init__.py\", line 169, in reload\r\n",
      "    _bootstrap._exec(spec, module)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\r\n",
      "    line for line in traceback.format_stack()\r\n",
      "\r\n",
      "\r\n",
      "  matplotlib.use('Agg')\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:13:10 [INFO]\t[EVAL] Finished, Epoch=10, bbox_map=3.030303 .\r\n",
      "2023-09-29 20:13:12 [INFO]\tModel saved in output/yolov3_darknet53/best_model.\r\n",
      "2023-09-29 20:13:13 [INFO]\tModel saved in output/yolov3_darknet53/epoch_10.\r\n",
      "2023-09-29 20:13:13 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_10, bbox_map=3.03030303030303\r\n",
      "2023-09-29 20:13:33 [INFO]\t[TRAIN] Epoch=11/40, Step=28/28, loss=18.936295, lr=3.8e-05, time_each_step=0.47s, eta=0:10:1\r\n",
      "2023-09-29 20:13:33 [INFO]\t[TRAIN] Epoch 11 finished, loss=19.788343, lr=3.7e-05 .\r\n",
      "2023-09-29 20:13:53 [INFO]\t[TRAIN] Epoch=12/40, Step=28/28, loss=16.940201, lr=4.2e-05, time_each_step=0.53s, eta=0:10:6\r\n",
      "2023-09-29 20:13:53 [INFO]\t[TRAIN] Epoch 12 finished, loss=18.052126, lr=4e-05 .\r\n",
      "2023-09-29 20:14:14 [INFO]\t[TRAIN] Epoch=13/40, Step=28/28, loss=20.16206, lr=4.5e-05, time_each_step=0.48s, eta=0:9:38\r\n",
      "2023-09-29 20:14:14 [INFO]\t[TRAIN] Epoch 13 finished, loss=17.225878, lr=4.4e-05 .\r\n",
      "2023-09-29 20:14:34 [INFO]\t[TRAIN] Epoch=14/40, Step=28/28, loss=14.010544, lr=4.9e-05, time_each_step=0.45s, eta=0:9:33\r\n",
      "2023-09-29 20:14:34 [INFO]\t[TRAIN] Epoch 14 finished, loss=17.414074, lr=4.7e-05 .\r\n",
      "2023-09-29 20:14:54 [INFO]\t[TRAIN] Epoch=15/40, Step=28/28, loss=20.573837, lr=5.2e-05, time_each_step=0.46s, eta=0:8:40\r\n",
      "2023-09-29 20:14:54 [INFO]\t[TRAIN] Epoch 15 finished, loss=17.525873, lr=5.1e-05 .\r\n",
      "2023-09-29 20:15:16 [INFO]\t[TRAIN] Epoch=16/40, Step=28/28, loss=15.079385, lr=5.6e-05, time_each_step=0.48s, eta=0:8:37\r\n",
      "2023-09-29 20:15:16 [INFO]\t[TRAIN] Epoch 16 finished, loss=17.256001, lr=5.4e-05 .\r\n",
      "2023-09-29 20:15:37 [INFO]\t[TRAIN] Epoch=17/40, Step=28/28, loss=13.451617, lr=5.9e-05, time_each_step=0.51s, eta=0:9:13\r\n",
      "2023-09-29 20:15:37 [INFO]\t[TRAIN] Epoch 17 finished, loss=16.503298, lr=5.8e-05 .\r\n",
      "2023-09-29 20:15:57 [INFO]\t[TRAIN] Epoch=18/40, Step=28/28, loss=15.290374, lr=6.3e-05, time_each_step=0.48s, eta=0:8:17\r\n",
      "2023-09-29 20:15:57 [INFO]\t[TRAIN] Epoch 18 finished, loss=17.068333, lr=6.1e-05 .\r\n",
      "2023-09-29 20:16:17 [INFO]\t[TRAIN] Epoch=19/40, Step=28/28, loss=15.940798, lr=6.6e-05, time_each_step=0.49s, eta=0:7:36\r\n",
      "2023-09-29 20:16:17 [INFO]\t[TRAIN] Epoch 19 finished, loss=16.485748, lr=6.5e-05 .\r\n",
      "2023-09-29 20:16:38 [INFO]\t[TRAIN] Epoch=20/40, Step=28/28, loss=21.858986, lr=7e-05, time_each_step=0.48s, eta=0:7:16\r\n",
      "2023-09-29 20:16:38 [INFO]\t[TRAIN] Epoch 20 finished, loss=15.616774, lr=6.8e-05 .\r\n",
      "2023-09-29 20:16:38 [INFO]\tStart to evaluating(total_samples=98, total_steps=9)...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:09<00:00,  1.02s/it]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:16:47 [INFO]\t[EVAL] Finished, Epoch=20, bbox_map=2.721541 .\r\n",
      "2023-09-29 20:16:48 [INFO]\tModel saved in output/yolov3_darknet53/epoch_20.\r\n",
      "2023-09-29 20:16:48 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_10, bbox_map=3.03030303030303\r\n",
      "2023-09-29 20:17:08 [INFO]\t[TRAIN] Epoch=21/40, Step=28/28, loss=14.668419, lr=7.3e-05, time_each_step=0.48s, eta=0:6:49\r\n",
      "2023-09-29 20:17:08 [INFO]\t[TRAIN] Epoch 21 finished, loss=15.361101, lr=7.2e-05 .\r\n",
      "2023-09-29 20:17:27 [INFO]\t[TRAIN] Epoch=22/40, Step=28/28, loss=16.022993, lr=7.7e-05, time_each_step=0.46s, eta=0:6:18\r\n",
      "2023-09-29 20:17:27 [INFO]\t[TRAIN] Epoch 22 finished, loss=15.28491, lr=7.5e-05 .\r\n",
      "2023-09-29 20:17:48 [INFO]\t[TRAIN] Epoch=23/40, Step=28/28, loss=14.622307, lr=8e-05, time_each_step=0.46s, eta=0:5:47\r\n",
      "2023-09-29 20:17:48 [INFO]\t[TRAIN] Epoch 23 finished, loss=14.947395, lr=7.9e-05 .\r\n",
      "2023-09-29 20:18:08 [INFO]\t[TRAIN] Epoch=24/40, Step=28/28, loss=16.607906, lr=8.4e-05, time_each_step=0.47s, eta=0:5:49\r\n",
      "2023-09-29 20:18:08 [INFO]\t[TRAIN] Epoch 24 finished, loss=14.639649, lr=8.2e-05 .\r\n",
      "2023-09-29 20:18:28 [INFO]\t[TRAIN] Epoch=25/40, Step=28/28, loss=13.441498, lr=8.7e-05, time_each_step=0.48s, eta=0:5:20\r\n",
      "2023-09-29 20:18:28 [INFO]\t[TRAIN] Epoch 25 finished, loss=14.247098, lr=8.6e-05 .\r\n",
      "2023-09-29 20:18:51 [INFO]\t[TRAIN] Epoch=26/40, Step=28/28, loss=12.989596, lr=9.1e-05, time_each_step=0.45s, eta=0:5:5\r\n",
      "2023-09-29 20:18:51 [INFO]\t[TRAIN] Epoch 26 finished, loss=14.048978, lr=8.9e-05 .\r\n",
      "2023-09-29 20:19:12 [INFO]\t[TRAIN] Epoch=27/40, Step=28/28, loss=15.221613, lr=9.4e-05, time_each_step=0.48s, eta=0:5:12\r\n",
      "2023-09-29 20:19:12 [INFO]\t[TRAIN] Epoch 27 finished, loss=14.395905, lr=9.3e-05 .\r\n",
      "2023-09-29 20:19:32 [INFO]\t[TRAIN] Epoch=28/40, Step=28/28, loss=13.466746, lr=9.8e-05, time_each_step=0.48s, eta=0:4:32\r\n",
      "2023-09-29 20:19:32 [INFO]\t[TRAIN] Epoch 28 finished, loss=13.600471, lr=9.6e-05 .\r\n",
      "2023-09-29 20:19:52 [INFO]\t[TRAIN] Epoch=29/40, Step=28/28, loss=12.139558, lr=0.000101, time_each_step=0.45s, eta=0:4:7\r\n",
      "2023-09-29 20:19:52 [INFO]\t[TRAIN] Epoch 29 finished, loss=13.725653, lr=0.0001 .\r\n",
      "2023-09-29 20:20:13 [INFO]\t[TRAIN] Epoch=30/40, Step=28/28, loss=18.406803, lr=0.000105, time_each_step=0.51s, eta=0:3:36\r\n",
      "2023-09-29 20:20:13 [INFO]\t[TRAIN] Epoch 30 finished, loss=13.107048, lr=0.000103 .\r\n",
      "2023-09-29 20:20:13 [INFO]\tStart to evaluating(total_samples=98, total_steps=9)...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.51it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:20:19 [INFO]\t[EVAL] Finished, Epoch=30, bbox_map=8.899207 .\r\n",
      "2023-09-29 20:20:23 [INFO]\tModel saved in output/yolov3_darknet53/best_model.\r\n",
      "2023-09-29 20:20:24 [INFO]\tModel saved in output/yolov3_darknet53/epoch_30.\r\n",
      "2023-09-29 20:20:24 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_30, bbox_map=8.89920740617489\r\n",
      "2023-09-29 20:20:44 [INFO]\t[TRAIN] Epoch=31/40, Step=28/28, loss=13.893236, lr=0.000108, time_each_step=0.44s, eta=0:3:20\r\n",
      "2023-09-29 20:20:44 [INFO]\t[TRAIN] Epoch 31 finished, loss=12.884614, lr=0.000107 .\r\n",
      "2023-09-29 20:21:04 [INFO]\t[TRAIN] Epoch=32/40, Step=28/28, loss=13.20516, lr=0.000112, time_each_step=0.51s, eta=0:2:52\r\n",
      "2023-09-29 20:21:04 [INFO]\t[TRAIN] Epoch 32 finished, loss=12.71328, lr=0.00011 .\r\n",
      "2023-09-29 20:21:25 [INFO]\t[TRAIN] Epoch=33/40, Step=28/28, loss=10.538862, lr=0.000115, time_each_step=0.51s, eta=0:2:30\r\n",
      "2023-09-29 20:21:25 [INFO]\t[TRAIN] Epoch 33 finished, loss=12.870336, lr=0.000114 .\r\n",
      "2023-09-29 20:21:47 [INFO]\t[TRAIN] Epoch=34/40, Step=28/28, loss=14.267422, lr=0.000119, time_each_step=0.47s, eta=0:2:16\r\n",
      "2023-09-29 20:21:47 [INFO]\t[TRAIN] Epoch 34 finished, loss=12.96079, lr=0.000117 .\r\n",
      "2023-09-29 20:22:06 [INFO]\t[TRAIN] Epoch=35/40, Step=28/28, loss=9.657946, lr=0.000122, time_each_step=0.44s, eta=0:2:1\r\n",
      "2023-09-29 20:22:06 [INFO]\t[TRAIN] Epoch 35 finished, loss=12.733802, lr=0.000121 .\r\n",
      "2023-09-29 20:22:27 [INFO]\t[TRAIN] Epoch=36/40, Step=28/28, loss=11.851501, lr=0.000125, time_each_step=0.48s, eta=0:1:27\r\n",
      "2023-09-29 20:22:27 [INFO]\t[TRAIN] Epoch 36 finished, loss=12.677644, lr=0.000124 .\r\n",
      "2023-09-29 20:22:48 [INFO]\t[TRAIN] Epoch=37/40, Step=28/28, loss=10.585945, lr=0.000125, time_each_step=0.52s, eta=0:1:13\r\n",
      "2023-09-29 20:22:48 [INFO]\t[TRAIN] Epoch 37 finished, loss=12.890152, lr=0.000125 .\r\n",
      "2023-09-29 20:23:09 [INFO]\t[TRAIN] Epoch=38/40, Step=28/28, loss=13.437053, lr=0.000125, time_each_step=0.49s, eta=0:0:54\r\n",
      "2023-09-29 20:23:09 [INFO]\t[TRAIN] Epoch 38 finished, loss=12.033753, lr=0.000125 .\r\n",
      "2023-09-29 20:23:32 [INFO]\t[TRAIN] Epoch=39/40, Step=28/28, loss=9.465956, lr=0.000125, time_each_step=0.54s, eta=0:0:31\r\n",
      "2023-09-29 20:23:32 [INFO]\t[TRAIN] Epoch 39 finished, loss=11.748258, lr=0.000125 .\r\n",
      "2023-09-29 20:23:54 [INFO]\t[TRAIN] Epoch=40/40, Step=28/28, loss=9.490839, lr=0.000125, time_each_step=0.5s, eta=0:0:11\r\n",
      "2023-09-29 20:23:54 [INFO]\t[TRAIN] Epoch 40 finished, loss=12.070151, lr=0.000125 .\r\n",
      "2023-09-29 20:23:54 [INFO]\tStart to evaluating(total_samples=98, total_steps=9)...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:08<00:00,  1.09it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:24:03 [INFO]\t[EVAL] Finished, Epoch=40, bbox_map=33.137789 .\r\n",
      "2023-09-29 20:24:07 [INFO]\tModel saved in output/yolov3_darknet53/best_model.\r\n",
      "2023-09-29 20:24:09 [INFO]\tModel saved in output/yolov3_darknet53/epoch_40.\r\n",
      "2023-09-29 20:24:09 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_40, bbox_map=33.13778888751509\r\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.labels)\n",
    "model = pdx.det.YOLOv3(num_classes=num_classes, backbone='DarkNet53')\n",
    "model.train(\n",
    "    num_epochs=40,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=12,\n",
    "    log_interval_steps=28,\n",
    "    eval_dataset=eval_dataset,\n",
    "    learning_rate=0.000125,\n",
    "    lr_decay_epochs=[210, 240],\n",
    "    save_interval_epochs=10,\n",
    "    early_stop=True,\n",
    "    save_dir='output/yolov3_darknet53',\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 评估与模型预测\n",
    "\n",
    "基于已经训练好的模型，我们对样本图像进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T12:29:37.390777Z",
     "iopub.status.busy": "2023-09-29T12:29:37.390197Z",
     "iopub.status.idle": "2023-09-29T12:29:38.683273Z",
     "shell.execute_reply": "2023-09-29T12:29:38.682455Z",
     "shell.execute_reply.started": "2023-09-29T12:29:37.390731Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:29:38 [INFO]\tModel[YOLOv3] loaded.\r\n",
      "2023-09-29 20:29:38 [INFO]\tThe visualized result is saved as /home/aistudio/visualize_test_image.jpg\r\n"
     ]
    }
   ],
   "source": [
    "import paddlex as pdx\n",
    "model = pdx.load_model('output/yolov3_darknet53/best_model')\n",
    "image_name = '/home/aistudio/test_image.jpg'\n",
    "result = model.predict(image_name)\n",
    "# result\n",
    "# 将result 进行可视化，并保存到指定路径\n",
    "pdx.det.visualize(image_name, result, threshold=0.05, save_dir='/home/aistudio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 整合进入基础gradio界面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义检测函数。这依赖于已经训练好的现成的best_model。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T16:16:06.494065Z",
     "iopub.status.busy": "2023-09-29T16:16:06.493524Z",
     "iopub.status.idle": "2023-09-29T16:16:06.498952Z",
     "shell.execute_reply": "2023-09-29T16:16:06.497766Z",
     "shell.execute_reply.started": "2023-09-29T16:16:06.494031Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddlex as pdx\n",
    "from paddlex.det import transforms\n",
    "\n",
    "# 目标检测函数\n",
    "# INPUT：用户上传的图片\n",
    "# OUTPUT：图片经目标检测的返图\n",
    "def detect(input_image):\n",
    "    \n",
    "    # FILL TEMPORAIRLY to test the front-end look\n",
    "    output_image = Image.open('visualize_test_image.jpg')\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改Gradio的设计布局，加入面向林火监测的烟火目标检测模块。（为避免混淆，将之前 **无yolo版本**部署的网页的后台终端，按`^C`终止。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T16:16:30.164942Z",
     "iopub.status.busy": "2023-09-29T16:16:30.164369Z",
     "iopub.status.idle": "2023-09-29T16:16:30.247918Z",
     "shell.execute_reply": "2023-09-29T16:16:30.247241Z",
     "shell.execute_reply.started": "2023-09-29T16:16:30.164885Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/gradio/deprecation.py:40: UserWarning: `width` is deprecated in `Interface()`, please use it within `launch()` instead.\r\n",
      "  warnings.warn(value)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\r\n",
      "\r\n",
      "To create a public link, set `share=True` in `launch()`.\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在Gradio UI中增加新的组件\n",
    "with gr.Row():\n",
    "        with gr.Tab(\"上传图片\"):\n",
    "            image_input = gr.Image()\n",
    "            img_analysis_button = gr.Button(\"分析图片\")\n",
    "        with gr.Tab(\"上传视频\"):\n",
    "            video_input = gr.Video()\n",
    "            video_analysis_button = gr.Button(\"分析视频\")\n",
    "        analysis_result = gr.Textbox(label=\"分析结果\")\n",
    "        \n",
    "        \n",
    "    with gr.Tab(\"建议\"):\n",
    "        text_output = gr.Textbox(label=\"输出\")\n",
    "    text_button = gr.Button(\"获取建议\")\n",
    "\n",
    "    with gr.Tab(\"烟火元素置信度分析(适用林火)\"):  # 新增Row\n",
    "        judge_image_output = gr.Textbox(label=\"分析判断结果\", image_mode='fixed', width=600)\n",
    "    judge_button = gr.Button(\"分析判断图片\")\n",
    "        \n",
    "    with gr.Tab(\"烟火目标检测可视化(适用林火)\"):  # 新增Row\n",
    "        detected_image_output = gr.Image(label=\"目标检测结果\", image_mode='fixed', width=600)  # 新增图像输出组件\n",
    "    detect_button = gr.Button(\"显示目标检测结果\")  # 新增按钮\n",
    "    \n",
    "    img_analysis_button.click(image_analysis, inputs=image_input, outputs=analysis_result) # 将按钮与image_analysis函数关联\n",
    "    video_analysis_button.click(video_analysis, inputs=video_input, outputs=analysis_result) # 将按钮与video_analysis函数关联\n",
    "\n",
    "    text_button.click(main_app, inputs=analysis_result, outputs=text_output) # 将按钮与main_app函数关联\n",
    "    \n",
    "    detect_button.click(detect, inputs=image_input, outputs=detected_image_output)  # 将按钮与detect函数关联\n",
    "    judge_button.click(judge, inputs=image_input, outputs=judge_image_output)  # 将按钮与judge_query函数关联\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常情况，访问生成的预览url你将看到类似下面的界面。\n",
    "\n",
    "<img src=\"https://img-blog.csdnimg.cn/dd881aec57db4387a70c43ea3d4eb2f4.png\" alt=\"withYOLO_gui.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "你可以使用自己图片进行自由测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、总结\n",
    "\n",
    "我们使用 Salesforce 开源的 **BLIP** 模型，将上传的图像解析为描述性文本；利用百度飞桨的 ERNIE 模型配合定制知识库，分析图像解析得到的文本，生成专业林业管理员视角的专业行动建议。该项目还结合了 飞桨PaddleX 进行目标检测标记，以便更精确地定位烟火源。\n",
    "\n",
    "该项目预期为林业安全管理起到高效的辅助作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
