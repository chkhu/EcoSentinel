import requests  # ç”¨äºå‘é€ HTTP è¯·æ±‚
import json  # ç”¨äºå¤„ç† JSON æ•°æ®
import gradio as gr  # ç”¨gradioåˆ›å»ºå›¾å½¢ç”¨æˆ·ç•Œé¢
import io  # ç”¨äºå¤„ç†å­—èŠ‚æµ
from PIL import Image
import numpy as np
# import cv2
# import paddlex as pdx
# from paddlex.det import transforms


# æ–‡å¿ƒAIçš„API Keyå’ŒSecret Keyï¼Œç”¨äºé“¾æ¥æ–‡å¿ƒå¤§æ¨¡å‹
SC_API_KEY = "Ge1lZ7If6RUzKuIqvpqR5MY2"
SC_SECRET_KEY = "cEUo45RrQAgBjr1oVg8Y9kxG155fYERB"

# salesforce BLIP çš„inference API reference KEY
API_URL_BLIP = "https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base"
headers_BLIP = {"Authorization": "Bearer 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"}

# çƒŸç«æ£€æµ‹ï¼ˆåˆ¤æ–­ï¼‰API reference KEY
API_URL_FIRE_VIT = "https://api-inference.huggingface.co/models/EdBianchi/vit-fire-detection"
headers_FIRE_VIT = {"Authorization": "Bearer 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"}

# è·å–ç™¾åº¦AIçš„access_tokenï¼ˆè¾“å…¥SC_API_KEY å’Œ SC_SECRET_KEYï¼Œè¾“å‡ºaccess_tokenï¼‰
def get_access_token(): 
    url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={SC_API_KEY}&client_secret={SC_SECRET_KEY}" # æ‹¼æ¥ request URL
    payload = ""
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
    }
    response = requests.request("POST", url, headers=headers, data=payload) # å‘é€ HTTP POST è¯·æ±‚ï¼Œè¿”å›ä¸€ä¸ªresponseå¯¹è±¡
    print("ACCESS_TOKEN OBTAINED: \n" + response.text + "\n")
    return str(response.json().get("access_token"))


# è‡ªå®šä¹‰çš„çŸ¥è¯†åº“å­—ç¬¦ä¸²ï¼Œç”¨äºä¸ªæ€§åŒ–å®šåˆ¶æ–‡å¿ƒå¤§æ¨¡å‹
knowledge_base = "æ—ä¸šç®¡ç†å’Œåº”æ€¥æ¶ˆé˜²çš„ä¸“ä¸šçŸ¥è¯†"  

# # ä¸ºåº”å¯¹å¤šæ¬¡åˆ†æè¯·æ±‚ï¼Œåˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰ç”Ÿæˆçš„æ–‡æœ¬ã€‚
# generated_texts = []

# æ–‡å¿ƒAPIçš„è°ƒç”¨å‡½æ•°
# INPUTï¼šç”¨æˆ·çš„è¾“å…¥æ–‡æœ¬
# OUTPUTï¼šæ–‡å¿ƒçš„å›ç­”æ–‡æœ¬
def main_app(input_text):
    # æ‹¼æ¥ URLï¼Œæ–‡å¿ƒçš„base_url + access token, åªæœ‰æ‹¥æœ‰æœ‰æ•ˆçš„access_tokenï¼Œæ‰èƒ½æˆåŠŸè°ƒç”¨æ–‡å¿ƒAPIã€‚
    # get_access_token()å‡½æ•°ä¼šå‘é€ä¸€ä¸ª HTTP POST è¯·æ±‚åˆ°ç™¾åº¦ è·å–access_tokenã€‚ å…·ä½“çš„å®ç°åœ¨ä¸‹é¢ã€‚
    url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token=" + get_access_token()
    payload = json.dumps({  # å°† Python å¯¹è±¡è½¬æ¢ç¼–ç æˆ JSON å­—ç¬¦ä¸²
        "messages": [   # æ‹¼æ¥å‡ºå®Œæ•´queryï¼ŒåŒ…å«ä¸‰éƒ¨åˆ†ï¼šå¼•å¯¼è¯ã€çŸ¥è¯†åº“ã€åœºæ™¯æè¿°
            {
                "role": "user",
                "content": "å‡å¦‚ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šæ—ä¸šå®‰å…¨ç®¡ç†å‘˜ï¼Œç†ŸçŸ¥ï¼š" + knowledge_base + 
                    "è¦æ ¹æ®ä¸‹é¢çš„æè¿°ç»™å‡ºä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œï¼ˆè¦æ±‚å›ç­”ä¸­åªéœ€å«æœ‰è§£å†³æ–¹æ¡ˆï¼Œå¹¶ä¸”æ–¹æ¡ˆåº”è¯¥ä¸»è¦é¢å‘æ—ä¸šæ¶ˆé˜²éƒ¨åˆ†æˆ–è€…æ—ä¸šå®‰å…¨å‘˜æå‡ºï¼‰ï¼š" + 
                    input_text,
            }
        ]
    })
    headers = { # è®¾ç½® HTTP è¯·æ±‚çš„å¤´éƒ¨ä¿¡æ¯
        'Content-Type': 'application/json'
    }
    response = requests.request("POST", url, headers=headers, data=payload) # å‘é€ HTTP POST è¯·æ±‚ï¼Œè¿”å›ä¸€ä¸ªresponseå¯¹è±¡
    result = response.json().get("result")  # ä»responseå¯¹è±¡ä¸­æå–å‡º JSON æ•°æ®ï¼ˆå›ç­”æ–‡æœ¬ï¼‰
    print("WENXIN RESPONSE:\n" + result + "\n") # log for debugging
    return result

def elaborate_description(input_text):
    url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token=" + get_access_token()
    payload = json.dumps({  # å°† Python å¯¹è±¡è½¬æ¢ç¼–ç æˆ JSON å­—ç¬¦ä¸²
        "messages": [   # æ‹¼æ¥å‡ºå®Œæ•´queryï¼ŒåŒ…å«ä¸‰éƒ¨åˆ†ï¼šå¼•å¯¼è¯ã€çŸ¥è¯†åº“ã€åœºæ™¯æè¿°
            {
                "role": "user",
                "content": "è¯·ä½ æ ¹æ®ä¸‹é¢çš„æè¿°æ–‡å­—ï¼Œåˆç†åœ°æ‰©å†™ï¼ˆæ³¨æ„æ‰©å†™åçš„æ–‡å­—åº”è¯¥æ˜¯å®¢è§‚ã€å†·é™çš„ã€æè¿°æ€§çš„æ—ä¸šç®¡ç†æœ¯è¯­ï¼‰ä¸åº”è¯¥æœ‰é™„åŠ çš„åŸå› åˆ†æã€æªæ–½å»ºè®®å’Œæ€»ç»“"  + 
                    input_text,
            }
        ]
    })
    headers = { # è®¾ç½® HTTP è¯·æ±‚çš„å¤´éƒ¨ä¿¡æ¯
        'Content-Type': 'application/json'
    }
    response = requests.request("POST", url, headers=headers, data=payload) # å‘é€ HTTP POST è¯·æ±‚ï¼Œè¿”å›ä¸€ä¸ªresponseå¯¹è±¡
    result = response.json().get("result")  # ä»responseå¯¹è±¡ä¸­æå–å‡º JSON æ•°æ®ï¼ˆå›ç­”æ–‡æœ¬ï¼‰
    print("WENXIN RESPONS(ELABORATE):\n" + result + "\n") # log for debugging
    return result


# BLIP APIçš„è°ƒç”¨å‡½æ•°
def BLIP_query(image_data):
    response = requests.post(API_URL_BLIP, headers=headers_BLIP, data=image_data)
    # åœ¨BLIP_queryè°ƒç”¨åæ·»åŠ è¿™è¡Œ
    return response.json()

# å›¾ç‰‡åˆ†æå‡½æ•°
# INPUTï¼šç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
# OUTPUTï¼šå›¾ç‰‡åˆ†ææ–‡æœ¬
def image_analysis(input_image):

    # # DEBUG: ä¿å­˜input_imageåˆ°æœ¬åœ°
    # cv2.imwrite('temp.jpg', input_image)
    # print("IMAGE ARRAY MAX VALUE" + str(input_image.max())) # 255

    # å°†è¾“å…¥çš„input_image(numpyæ•°ç»„ç±»å‹)è½¬æˆqueryå‡½æ•°å¯ä»¥æ¥å—çš„Bytesç±»å‹
    img = Image.fromarray(input_image.astype(np.uint8))  # éœ€è¦è½¬æ¢ä¸º uint8ï¼ŒèŒƒå›´ [0, 255]    
    img_byte_arr = io.BytesIO()  # åˆ›å»ºä¸€ä¸ªå­—èŠ‚æµå¯¹è±¡
    img.save(img_byte_arr, format='PNG')  # å°†å›¾åƒä¿å­˜åˆ°å­—èŠ‚æµä¸­ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„æ ¼å¼ï¼Œä¾‹å¦‚ 'JPEG'ï¼Œè¿™é‡Œç”¨ 'PNG'
    img_byte_arr = img_byte_arr.getvalue()  # è·å–å­—èŠ‚æµçš„å€¼

    # è°ƒç”¨ BLIP_query å‡½æ•°
    output = BLIP_query(img_byte_arr)

    # # DEBUG
    print("âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨BLIP output:", output)

    # # DEBUG
    # print("TYPE OF OUTPUT OF QUERY\n")
    # print(type(output)) # list
    
    # å–å‡ºåˆ—è¡¨çš„0å·å…ƒç´ ï¼Œç„¶åç”¨ ['generated_text'] å–å‡ºå­—å…¸ä¸­çš„å€¼
    newly_generated_text = output[0]['generated_text'] 
    # generated_texts.append(newly_generated_text)
    # generated_text = generated_texts[-1] #  å–åˆ—è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œç¡®ä¿æ¯æ¬¡éƒ½æ˜¯æœ€æ–°çš„æ–‡æœ¬

    # å°†newly_generated_textä¼ ç»™æ–‡å¿ƒAPIï¼Œè¿›è¡Œæ‰©å†™
    elaborated_text = elaborate_description(newly_generated_text)

    # æœ€åï¼Œè¿”å›ç”Ÿæˆçš„æ–‡æœ¬
    return elaborated_text



# ç›®æ ‡æ£€æµ‹å‡½æ•°
# INPUTï¼šç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
# OUTPUTï¼šå›¾ç‰‡ç»ç›®æ ‡æ£€æµ‹çš„è¿”å›¾
def detect(input_image):
    # # è°ƒç”¨å·²ç»è®­ç»ƒå¥½çš„`best_model`è¿›è¡Œé¢„æµ‹
    # model = pdx.load_model('../best_model')

    # # å°†input_imageè½¬æˆ.jpgæ ¼å¼ï¼Œä¿å­˜åœ¨../ç›®å½•ä¸‹

    # # å°†è¾“å…¥çš„input_image(numpyæ•°ç»„ç±»å‹)è½¬æˆqueryå‡½æ•°å¯ä»¥æ¥å—çš„Bytesç±»å‹
    # img = Image.fromarray(input_image.astype(np.uint8))  # éœ€è¦è½¬æ¢ä¸º uint8ï¼ŒèŒƒå›´ [0, 255]
    # img_byte_arr = io.BytesIO()  # åˆ›å»ºä¸€ä¸ªå­—èŠ‚æµå¯¹è±¡
    # img.save(img_byte_arr, format='JPG')  # å°†å›¾åƒä¿å­˜åˆ°å­—èŠ‚æµä¸­ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„æ ¼å¼ï¼Œä¾‹å¦‚ 'JPEG'ï¼Œè¿™é‡Œç”¨ 'PNG'
    # img_byte_arr = img_byte_arr.getvalue()  # è·å–å­—èŠ‚æµçš„å€¼

    # result = model.predict(img_byte_arr)
    
    # # å°†result è¿›è¡Œå¯è§†åŒ–ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    # pdx.det.visualize(image_name, result, threshold=0.05, save_dir='../')
    
    # # é‡æ–°æ‰“å¼€å›¾åƒå¹¶è¿”å›
    # output_image = Image.open('../visualize_test_image.jpg')
    
    # FILL TEMPORAIRLY to test the front-end look
    output_image = Image.open('../visualized_test_image_temp.jpg')

    return output_image


def judge_query(image_data):
    response = requests.post(API_URL_FIRE_VIT, headers=headers_FIRE_VIT, data=image_data)
    return response.json()

def judge(input_image):
    # å°†è¾“å…¥çš„input_image(numpyæ•°ç»„ç±»å‹)è½¬æˆqueryå‡½æ•°å¯ä»¥æ¥å—çš„Bytesç±»å‹
    img = Image.fromarray(input_image.astype(np.uint8))  # éœ€è¦è½¬æ¢ä¸º uint8ï¼ŒèŒƒå›´ [0, 255]    
    img_byte_arr = io.BytesIO()  # åˆ›å»ºä¸€ä¸ªå­—èŠ‚æµå¯¹è±¡
    img.save(img_byte_arr, format='PNG')  # å°†å›¾åƒä¿å­˜åˆ°å­—èŠ‚æµä¸­ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„æ ¼å¼ï¼Œä¾‹å¦‚ 'JPEG'ï¼Œè¿™é‡Œç”¨ 'PNG'
    img_byte_arr = img_byte_arr.getvalue()  # è·å–å­—èŠ‚æµçš„å€¼

    output = judge_query(img_byte_arr)

    # # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
    # if 'error' in output:
    #     # å¤„ç†é”™è¯¯æƒ…å†µï¼Œä¾‹å¦‚è¿”å›é”™è¯¯ä¿¡æ¯æˆ–é‡è¯•è¯·æ±‚
    #     return f"Error: {output['error']}"

    # # DEBUG
    print("âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨VIT output:", output)

    # å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œåˆ™æ ¼å¼åŒ–è¾“å‡º
    formatted_output = "çƒŸç«å…ƒç´ ç½®ä¿¡åº¦åˆ†æç»“æœï¼š\n"

    # æå–å‡ºoutputä¸­labelå€¼ä¸ºNormalã€Fireã€Smokeçš„ç½®ä¿¡åº¦
    for item in output:
        if item['label'] == 'Normal':
            normal_score = item['score']
            formatted_output += f"Normalç½®ä¿¡åº¦: {item['score']}\n"
        elif item['label'] == 'Fire':
            fire_score = item['score']
            formatted_output += f"Fireç½®ä¿¡åº¦: {item['score']}\n"
        elif item['label'] == 'Smoke':
            smoke_score = item['score']
            formatted_output += f"Smokeç½®ä¿¡åº¦: {item['score']}\n"

    formatted_output += "\nçƒŸç«ç›®æ ‡åˆ¤æ–­ç»“æœï¼š\n"
    if fire_score > normal_score or smoke_score > normal_score:
        formatted_output += "âš ï¸å­˜åœ¨ç«æƒ…"
    else:
        formatted_output += "ğŸƒä¸å­˜åœ¨ç«æƒ…"

    judgement_output = formatted_output

    # æœ€åï¼Œè¿”å›ç”Ÿæˆçš„æ–‡æœ¬
    return judgement_output


# åœ¨Gradio UIä¸­å¢åŠ æ–°çš„ç»„ä»¶
with gr.Blocks() as demo:
    with gr.Row():
        image_input = gr.Image()
        analysis_result = gr.Textbox(label="åˆ†æç»“æœ")
    analysis_button = gr.Button("åˆ†æå›¾ç‰‡")
        
    with gr.Tab("å»ºè®®"):
        text_output = gr.Textbox(label="è¾“å‡º")
    text_button = gr.Button("è·å–å»ºè®®")

    with gr.Tab("çƒŸç«å…ƒç´ ç½®ä¿¡åº¦åˆ†æ(é€‚ç”¨æ—ç«)"):  # æ–°å¢Row
        judge_image_output = gr.Textbox(label="åˆ†æåˆ¤æ–­ç»“æœ", image_mode='fixed', width=600)
    judge_button = gr.Button("åˆ†æåˆ¤æ–­å›¾ç‰‡")
        
    with gr.Tab("çƒŸç«ç›®æ ‡æ£€æµ‹å¯è§†åŒ–(é€‚ç”¨æ—ç«)"):  # æ–°å¢Row
        detected_image_output = gr.Image(label="ç›®æ ‡æ£€æµ‹ç»“æœ", image_mode='fixed', width=600)  # æ–°å¢å›¾åƒè¾“å‡ºç»„ä»¶
    detect_button = gr.Button("æ˜¾ç¤ºç›®æ ‡æ£€æµ‹ç»“æœ")  # æ–°å¢æŒ‰é’®
    
    analysis_button.click(image_analysis, inputs=image_input, outputs=analysis_result) # å°†æŒ‰é’®ä¸image_analysiså‡½æ•°å…³è”
    text_button.click(main_app, inputs=analysis_result, outputs=text_output) # å°†æŒ‰é’®ä¸main_appå‡½æ•°å…³è”
    detect_button.click(detect, inputs=image_input, outputs=detected_image_output)  # å°†æŒ‰é’®ä¸detectå‡½æ•°å…³è”
    judge_button.click(judge, inputs=image_input, outputs=judge_image_output)  # å°†æŒ‰é’®ä¸judge_queryå‡½æ•°å…³è”

demo.launch()